# メモリ最適化実装ガイド

## 概要

この実装では、大規模な時系列データを効率的に扱うため、メモリ使用量を最小限に抑えるアーキテクチャを採用しています。

## 更新内容（2025-07-04）

### 完全な永続化機能の実装
- **すべてのCSVデータを自動的にParquet形式で永続化**
  - データ量に関わらずすべてのデータをParquet形式で保存
  - データの再利用性が大幅に向上
  - 重複データの自動マージ機能

- **永続化の進捗表示**
  - リアルタイムで永続化状態を表示
  - ユーザーへの視覚的フィードバック

- **既存Parquetファイルの自動再利用**
  - 同じ年月のデータは自動的にマージ
  - タイムスタンプベースの重複排除

## 主な最適化手法

### 1. メタデータとデータの分離
- CSVインポート時、パラメータのメタデータ（名前、単位、統計情報）のみをメモリに保持
- 実際のデータはオンデマンドでロード

### 2. データ参照管理システム
- `DataReferenceManager`: データの場所と状態を管理
- メモリキャッシュにLRU evictionポリシーを実装
- 大規模データは自動的にファイルシステムに永続化

### 3. データウィンドウイング
- チャート表示に必要な時間範囲のデータのみロード
- ズーム・パン操作に応じて動的にデータを取得
- `useDataWindow`フックで時間ベースのチャンク管理

### 4. 自動ダウンサンプリング
- デフォルトで1000ポイントに自動ダウンサンプリング
- 複数の集約手法（平均、最小、最大、最初、最後）をサポート
- ズームレベルに応じた適応的ダウンサンプリング

### 5. メモリライフサイクル管理
- `useMemoryManager`フックでメモリ使用量を監視
- 閾値ベースの警告システム（50%、70%、85%、95%）
- 95%到達時の自動キャッシュクリア

## アーキテクチャ

```
┌─────────────────┐
│  CSV Import     │
└────────┬────────┘
         │
         ▼
┌─────────────────┐     ┌──────────────────┐
│ DataReference   │────▶│ MetadataCache    │
│   Manager       │     │ (Memory)         │
└────────┬────────┘     └──────────────────┘
         │
         ▼
┌─────────────────┐     ┌──────────────────┐
│ Data Storage    │────▶│ FileSystem/      │
│   Decision      │     │ IndexedDB        │
└────────┬────────┘     └──────────────────┘
         │
         ▼
┌─────────────────┐
│ On-demand       │
│ Data Loading    │
└─────────────────┘
```

## 使用方法

### 1. 最適化版ページへアクセス
```
http://localhost:3000/optimized
```

### 2. データインポート
- アップロードタブ: 直接CSVファイルをアップロード
- ファイルシステムタブ: ローカルディレクトリと連携

### 3. パラメータ選択
- メタデータのみを使用した軽量なパラメータリスト
- グループ化と検索機能
- 統計情報（最小、最大、平均）の表示

### 4. チャート作成
- 選択したパラメータのデータのみロード
- 初期表示は過去24時間分
- ズーム・パン操作でデータを動的に取得

### 5. メモリ監視
- リアルタイムメモリ使用量表示
- 警告レベルに応じた色分け
- 手動キャッシュクリア機能

## 永続化機能の詳細

### データフロー
1. **CSVアップロード** → 即座にメタデータを抽出してUI表示
2. **バックグラウンド処理** → Parquet形式への変換と保存
3. **自動マージ** → 同じ年月のデータは既存Parquetと統合
4. **オンデマンドロード** → チャート作成時に必要な部分のみ読み込み

### Parquetファイルの利点
- **高圧縮率**: CSVの1/5〜1/10のファイルサイズ
- **高速クエリ**: 列指向フォーマットで必要なデータのみアクセス
- **型安全**: データ型情報を保持
- **分析最適化**: DuckDBによる効率的なデータ処理

## パフォーマンス比較

### 従来の実装
- 100MBのCSVファイル → 約400MBのメモリ使用
- 全データを常にメモリに保持
- チャート追加ごとにデータ複製
- データの再利用不可

### 最適化版（更新後）
- 100MBのCSVファイル → 約20MBのメモリ使用（メタデータのみ）
- 表示に必要なデータのみロード
- 共有データバッファーによる効率化
- **すべてのデータをParquet形式で永続化**
- **次回以降は高速にデータを再利用可能**

## 今後の拡張案

1. **WebWorkerによるバックグラウンド処理**
   - CSV解析を別スレッドで実行
   - UIの応答性向上

2. **プログレッシブレンダリング**
   - 低解像度データを先に表示
   - 高解像度データを段階的にロード

3. **インテリジェントプリフェッチ**
   - ユーザーの操作パターンを学習
   - 次に必要なデータを予測してプリロード

4. **圧縮アルゴリズムの適用**
   - データチャンクの圧縮保存
   - 転送量とストレージ使用量の削減